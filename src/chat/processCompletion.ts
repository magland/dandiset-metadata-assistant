/* eslint-disable @typescript-eslint/no-explicit-any */
import { QPTool, ToolExecutionContext, Chat, ChatMessage, CompletionRequest } from "./types";
import { AVAILABLE_MODELS } from "./availableModels";
import { getStoredOpenRouterApiKey } from "./apiKeyStorage";
import { parseCompletionStream } from "./parseCompletionStream";

// Retry configuration for rate limit errors
const MAX_RETRIES = 3;
const INITIAL_RETRY_DELAY_MS = 10000; // 10 seconds (rate limit is 10 req/min)

/**
 * Sleep for a given number of milliseconds
 */
const sleep = (ms: number) => new Promise((resolve) => setTimeout(resolve, ms));

/**
 * Check if an error is a rate limit error
 */
const isRateLimitError = (status: number, errorMessage: string): boolean => {
  return status === 429 || errorMessage.toLowerCase().includes("rate limit");
};

const processCompletion = async (
  chat: Chat,
  onPartialResponse: (messages: ChatMessage[]) => void,
  tools: QPTool[],
  initialSystemMessage: string,
  toolExecutionContext: ToolExecutionContext,
  signal?: AbortSignal,
): Promise<ChatMessage[]> => {
  const request: CompletionRequest = {
    model: chat.model,
    systemMessage: initialSystemMessage,
    messages: chat.messages,
    tools: tools.map((tool) => ({
      type: "function",
      function: tool.toolFunction,
    })),
    app: "dandiset-metadata-assistant",
  };

  const apiKey = getStoredOpenRouterApiKey();
  const headers: Record<string, string> = {
    "Content-Type": "application/json",
  };

  if (apiKey) {
    headers["x-openrouter-key"] = apiKey;
  }

  // Fetch with retry logic for rate limit errors
  let response: Response | null = null;
  let lastError: Error | null = null;

  for (let attempt = 0; attempt <= MAX_RETRIES; attempt++) {
    try {
      response = await fetch("https://qp-worker.neurosift.app/api/completion", {
        method: "POST",
        headers,
        body: JSON.stringify(request),
        signal,
      });

      if (response.ok) {
        break; // Success, exit retry loop
      }

      // Try to get detailed error message from response body
      let errorDetails = response.statusText || `HTTP ${response.status}`;
      try {
        const errorBody = await response.text();
        if (errorBody) {
          // Try to parse as JSON for structured error
          try {
            const errorJson = JSON.parse(errorBody);
            errorDetails = errorJson.error?.message || errorJson.message || errorJson.error || errorBody;
          } catch {
            // Not JSON, use raw text
            errorDetails = errorBody;
          }
        }
      } catch {
        // Couldn't read body, stick with statusText
      }

      // Check if this is a rate limit error and we should retry
      if (isRateLimitError(response.status, errorDetails) && attempt < MAX_RETRIES) {
        const delayMs = INITIAL_RETRY_DELAY_MS * Math.pow(2, attempt);
        console.warn(`Rate limit hit, retrying in ${delayMs / 1000}s (attempt ${attempt + 1}/${MAX_RETRIES})...`);

        // Update partial response to show waiting message
        onPartialResponse([
          {
            role: "assistant",
            content: `â³ Rate limit reached. Waiting ${Math.round(delayMs / 1000)} seconds before retrying (attempt ${attempt + 1}/${MAX_RETRIES})...`,
            model: chat.model,
            usage: { promptTokens: 0, completionTokens: 0, estimatedCost: 0 },
          },
        ]);

        await sleep(delayMs);
        continue; // Retry
      }

      // Not a rate limit error or out of retries
      lastError = new Error(`OpenRouter API error: ${errorDetails}`);
      break;
    } catch (err) {
      // Network error or abort
      if (err instanceof Error && err.name === "AbortError") {
        throw err; // Don't retry aborted requests
      }
      lastError = err instanceof Error ? err : new Error(String(err));

      // Only retry network errors if we have retries left
      if (attempt < MAX_RETRIES) {
        const delayMs = INITIAL_RETRY_DELAY_MS * Math.pow(2, attempt);
        console.warn(`Network error, retrying in ${delayMs / 1000}s...`);
        await sleep(delayMs);
        continue;
      }
      break;
    }
  }

  if (lastError) {
    throw lastError;
  }

  if (!response || !response.ok) {
    throw new Error("Failed to get response from API");
  }

  const reader = response.body?.getReader();
  if (!reader) {
    throw new Error("No response body");
  }

  const { assistantContent, toolCalls, promptTokens, completionTokens } =
    await parseCompletionStream(reader, (content) => {
      onPartialResponse([
        {
          role: "assistant",
          content,
          model: chat.model,
          usage: {
            promptTokens: 0,
            completionTokens: 0,
            estimatedCost: 0,
          },
        },
      ]);
    });

  const ret: ChatMessage[] = [];

  if (toolCalls) {
    ret.push({
      role: "assistant",
      content: assistantContent,
      tool_calls: toolCalls,
      model: chat.model,
      usage: {
        promptTokens,
        completionTokens: 0,
        estimatedCost: 0,
      },
    });
    onPartialResponse([...ret]);

    for (const toolCall of toolCalls) {
      if (toolCall.type !== "function") {
        throw new Error("Unexpected tool call type: " + toolCall.type);
      }
      const toolCallId = toolCall.id;
      const functionName = toolCall.function.name;
      const functionArgs = toolCall.function.arguments;
      const functionArgsParsed = JSON.parse(functionArgs || "{}");

      const tool = tools.find((t) => t.toolFunction.name === functionName);
      if (!tool) {
        throw new Error("Tool not found: " + functionName);
      }

      console.info(`Executing tool: ${functionName} with args:`, functionArgsParsed);
      let result: string;
      let newMessages: ChatMessage[] | undefined;
      try {
        const a = await tool.execute(
          functionArgsParsed,
          toolExecutionContext,
        );
        result = a.result;
        newMessages = a.newMessages;
      } catch (err) {
        console.warn(`Error executing tool "${functionName}":`, err);
        const errorMessage =
          err instanceof Error ? err.message : "Unknown error executing tool";
        const errorContent = `Error executing tool "${functionName}": ${errorMessage}`;
        ret.push({
          role: "tool",
          content: errorContent,
          tool_call_id: toolCallId,
        });
        onPartialResponse([...ret]);
        continue; // Proceed to next tool call
      }

      for (const m of newMessages || []) {
        ret.push(m);
      }
      ret.push({
        role: "tool",
        content: result,
        tool_call_id: toolCallId,
      });
      onPartialResponse([...ret]);
    }

    // Recursively process if there were tool calls
    const onPartialResponse2 = (a: ChatMessage[]) => {
      onPartialResponse([...ret, ...a]);
    };
    const x = await processCompletion(
      {
        ...chat,
        messages: [...chat.messages, ...ret],
      },
      onPartialResponse2,
      tools,
      initialSystemMessage,
      toolExecutionContext,
      signal,
    );

    return [...ret, ...x];
  }

  const estimatedCost = getEstimatedCostForModel(
    chat.model,
    promptTokens,
    completionTokens,
  );

  return [
    {
      role: "assistant",
      content: assistantContent,
      model: chat.model,
      usage: {
        promptTokens,
        completionTokens,
        estimatedCost,
      },
    },
  ];
};

const getEstimatedCostForModel = (
  model: string,
  promptTokens: number,
  completionTokens: number,
): number => {
  for (const m of AVAILABLE_MODELS) {
    if (m.model === model) {
      return (
        (m.cost.prompt * promptTokens + m.cost.completion * completionTokens) /
        1_000_000
      );
    }
  }
  return 0;
};

export default processCompletion;
